---
title: "Neural Network Fraud Detection"
author: "Ryan"
date: "`r Sys.Date()`"
format: html
---

# **Introduction**
This document outlines the step-by-step implementation of a Neural Network model for fraud detection.

## **1. Load Required Libraries**
We load the necessary libraries for deep learning, data preprocessing, and numerical computation.

```{r setup, include=FALSE}
library(tidyverse)  # For data manipulation
library(keras)      # For building neural networks
library(tensorflow) # Backend for Keras
library(reticulate) # Interface with Python if needed
```

### **Why These Libraries?**
- `tidyverse`: Simplifies data manipulation.
- `keras` & `tensorflow`: Used to build and train deep learning models.
- `reticulate`: Allows R to interface with Python (useful if needed).

## **2. Load Dataset**
Load the prepared dataset, which consists of an equal number of fraud and non-fraud cases.

```{r load-data}
df <- read.csv("../Data/Fraud_Subset_50_50_10k_each.csv")
str(df)
summary(df)
```

### **Considerations:**
- Use `str(df)` and `summary(df)` to understand the structure of the data.
- If needed, handle missing values or unexpected data types.

## **3. Data Preprocessing for Neural Network**
Neural networks perform best with normalized numerical data. We check for categorical variables and normalize numerical features.

```{r preprocessing}
# Convert categorical variables to factors (if necessary)
df$fraud <- as.factor(df$fraud)

# Normalize numerical features
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

df[, c("totalScanTimeInSeconds", "grandTotal", "scannedLineItemsPerSecond", "valuePerSecond", "lineItemVoidsPerPosition")] <- 
  lapply(df[, c("totalScanTimeInSeconds", "grandTotal", "scannedLineItemsPerSecond", "valuePerSecond", "lineItemVoidsPerPosition")], normalize)
```

### **Justifications for Preprocessing:**
- **Normalization:** Since neural networks are sensitive to scale, we normalize numeric features between 0 and 1.
- **Categorical Variables:** The `fraud` column is converted to a factor so it can be processed correctly.
- **Alternative Approaches:**
  - Standardization (Z-score normalization) could be used instead, depending on model performance.
  - One-hot encoding may be required for categorical variables, but it's not necessary for binary classification.

## **4. Train-Test Split**
To evaluate the model, we split the dataset into training and testing subsets.

```{r train-test-split}
set.seed(42)
trainIndex <- createDataPartition(df$fraud, p = 0.8, list = FALSE)
df_train <- df[trainIndex, ]
df_test <- df[-trainIndex, ]
```

### **Why This Split?**
- **80/20 split** is a standard practice in machine learning.
- Setting a seed ensures reproducibility.

## **5. Define and Train the Neural Network Model**
Neural networks can be structured in different ways. Here, we use a sequential model with three layers.

```{r neural-network}
nn_model <- keras_model_sequential() %>%
  layer_dense(units = 64, activation = "relu", input_shape = c(ncol(df_train) - 1)) %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

nn_model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_adam(),
  metrics = c("accuracy")
)

# Train the model
history <- nn_model %>% fit(
  x = as.matrix(df_train[, -ncol(df_train)]),  # Features
  y = as.numeric(df_train$fraud) - 1,  # Target variable (converted to 0/1)
  epochs = 10,
  batch_size = 32,
  validation_split = 0.2
)
```

### **Justifications for Model Choices:**
- **Dense Layers:**
  - 64 neurons â†’ 32 neurons â†’ 1 output neuron.
  - More layers or neurons could improve performance but increase training time.
- **Activation Functions:**
  - `relu` for hidden layers (effective for deep learning).
  - `sigmoid` for the output layer (binary classification).
- **Loss Function:**
  - `binary_crossentropy` is used for binary classification tasks.
- **Optimizer:**
  - `adam` is chosen for adaptive learning rates.
- **Epochs & Batch Size:**
  - 10 epochs (can be tuned higher if needed).
  - 32 batch size (can be adjusted for memory efficiency).

## **6. Evaluate Model Performance**
Once trained, we test the model on unseen data.

```{r model-evaluation}
nn_predictions <- predict(nn_model, as.matrix(df_test[, -ncol(df_test)]))
nn_pred_class <- ifelse(nn_predictions > 0.5, 1, 0)

confusionMatrix(as.factor(nn_pred_class), as.factor(df_test$fraud))
```

### **Evaluation Metrics:**
- **Confusion Matrix:** Helps analyze False Positives and False Negatives.
- **Alternative Metrics:** Precision, Recall, and F1-Score can be used for more detailed insights.

---

## **Next Steps: Implementing in Orange**
We will also create an Orange workflow for training and testing the neural network.
1. Load **Fraud_Subset_50_50_10k_each.csv** into Orange (`File` widget).
2. Normalize numeric variables (`Preprocessing` widget).
3. Use `Select Columns` to ensure correct feature selection.
4. Apply `Data Sampler` to create train/test splits.
5. Train the model using `Neural Network` widget.
6. Evaluate using `Test & Score`.
7. Compare results across different model types.

---

This document ensures that every step in the neural network training is justified and reproducible. Further improvements can be made by tuning hyperparameters, trying alternative architectures, or integrating different preprocessing techniques. ðŸš€
